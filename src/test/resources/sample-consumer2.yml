version: 1.1

consumerId: searcher

input:
  masters:
    - connection:
        address: 192.168.1.100
        port: 1234
      schemas:
        - name: "test_*"
          tables:
          - name: affair
            rowName: [id, name] # default id is not null, other can be null
          - name: file
            rowName: [id, name, uploader]
          - name: folder
            rowName: [id, name, uploader]
        - name: "simple"
          tables:
          - name: test
            rowName: [id, test]

    - connection:
        address: 192.168.1.200
        port: 1234
      schemas:
        - name: "test_*"
          tables:
          - name: affair
            rowName: [id, name] # default id is not null, other can be null
          - name: file
            rowName: [id, name, uploader]
          - name: folder
            rowName: [id, name, uploader]
        - name: "simple"
          tables:
          - name: test
            rowName: [id, test]

# input result class: com.github.zzt93.syncer.common.data.SyncData
#{
#  schemas: xxx
#  table: xxx
#  id: xid
#  row: {
#    id: xid
#    ...
#  }
#  extra: {
#    ...
#  }
#}

filter:
  - if:
      condition: "containRecord('tags')"
      ifBody:
      - statement: ["updateRecord('tags', T(SyncUtil).fromJson(records['tags'], T(String[])))"]
  - statement: ["#docType=table"]

  - if:
      condition: "table == 'task' && isWrite() && records[state] != 0"
      ifBody:
      - drop: {}

  - switcher:
      switch: "table"
      case: # support default branch
        "affair": ["#suffix = '-' + row['id']","#type = 'INDEX_AFFAIR'", "renameRecord('xx', 'yy')" ]
        "file": ["#suffix = '-' + row['id']","#type = 'INDEX_FILE'", "addRow('type', '0')"]
        "folder": ["#suffix = '-' + row['id']","#type = 'INDEX_FILE'", "addRow('type', '1')"]
  - statement: [ "#tags = row['tags']", "updateRecord('tags', new java.util.ArrayList())", "removeRecords('id', 'xid')"]
  - foreach:
      var: "tag"
      in: "#tags?.split('\n')"
      statement: ["#map = new java.util.HashMap()", "#map.put('des', #tag)", "row.get('tags').add(#map)"]


# filter result class: com.github.zzt93.syncer.common.data.SyncData
#{
#  schemas: xxx
#  table: xxx
#  id: xid
#  row: {
#    id: xid
#    ...
#  }
#  extra: {
#    ...
#  }
#}

# Special expression
# "row.*"
# "row.*.flatten"
# "extra.*"
# "extra.*.flatten"

output:
  elasticsearch:
    connection:
      clusterName: elasticsearch
      clusterNodes: ["192.168.1.100:9300"]
      user: elastic-user # optional if not enable security
      passwordFile: es-password # optional if not enable security
    requestMapping: # mapping from input data to es request
      enableExtraQuery: true
      retryOnUpdateConflict: 3
      index: "table + #suffix" # default: schema
      type: "#docType" # default: table
      documentId: "id" # default: id
      fieldsMapping: # default: records.*.flatten
        "records": "records.*.flatten"
    batch:
      size: 100
      delay: 1000
      maxRetry: 5
    refreshInMillis: 1000

  mysql:
    connection:
      address: ${HOST_ADDRESS}
      port: 3306
      user: xxx
      password: xxx
    rowMapping:
      schema: "'auth'"
      table: "table"
      id: "id"
      rows:
        "records": "records.*.flatten"
    batch:
      size: 100
      delay: 100
      maxRetry: 5
    failureLog:
      countLimit: 1000

