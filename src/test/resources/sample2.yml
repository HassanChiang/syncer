pipeline:

  input:
    mysql-masters:
      - connection:
          address: 192.168.1.100
          port: 1234
          user: root
          password-file: password
        schema:
          name: "*"
          tables:
            - name: affair
              row-name: [id, name] # default id is not null, other can be null
            - name: file
              row-name: [id, name, uploader]
            - name: folder
              row-name: [id, name, uploader]

      - connection:
          address: 192.168.1.100
          port: 1235
          user: root
          password-file: password
        schema:
          name: "*"
          tables:
            - name: affair
              row-name: [id, name]
            - name: file
              row-name: [id, name, uploader]
            - name: folder
              row-name: [id, name, uploader]

# input result class: com.github.zzt93.syncer.common.SyncData
#{
#  schema: xxx
#  table: xxx
#  id: xid
#  row: {
#    id: xid
#    ...
#  }
#  extra: {
#    ...
#  }
#}

  filter:
    - switcher:
        switch: "table"
        case: # support default branch
          "affair": ["#suffix = '-' + row['id']","#type = 'INDEX_AFFAIR'", "renameColumn('xx', 'yy')" ]
          "file": ["#suffix = '-' + row['id']","#type = 'INDEX_FILE'", "addRow('type', '0')"]
          "folder": ["#suffix = '-' + row['id']","#type = 'INDEX_FILE'", "addRow('type', '1')"]
    - statement: [ "#tags = row['tags']", "updateColumn('tags', new java.util.ArrayList())", "removeColumns('id', 'xid')"]
    - foreach:
        var: "tag"
        in: "#tags?.split('\n')"
        statement: ["#map = new java.util.HashMap()", "#map.put('des', #tag)", "row.get('tags').add(#map)"]


# filter result class: com.github.zzt93.syncer.common.SyncData
#{
#  schema: xxx
#  table: xxx
#  id: xid
#  row: {
#    id: xid
#    ...
#  }
#  extra: {
#    ...
#  }
#}

# Special expression
# "row.*"
# "row.*.flatten"
# "extra.*"
# "extra.*.flatten"

  output:
    elasticsearch:
      connection:
        cluster-name: elasticsearch
        cluster-nodes: ["192.168.1.100:9300"]
        user: elastic-user # optional if not enable security
        password-file: es-password # optional if not enable security
      document-mapping: # mapping from input data to document json
        index: "table + #suffix" # default schema
        type: "table" # default table
        document-id: "id" # default id
        fields-mapper: # rest row.* => row.*
          "row": "row.*.flatten"

    http:
      connection:
        address: 192.168.1.100
        port: 9700
      json-mapper:
        "data": "row.*"
        "type": "extra['type']"

